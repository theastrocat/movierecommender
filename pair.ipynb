{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the utility data (user, movie, rating, date)\n",
    "utility_df = pd.read_csv('data/u.data', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop the date column\n",
    "utility_df.drop(3, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup a SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Convert a Pandas DF to a Spark DF\n",
    "# also add column names (names used work with ALS model below)\n",
    "utility_spark_df = spark.createDataFrame(utility_df, [\"user\", \"movie\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|user|movie|rating|\n",
      "+----+-----+------+\n",
      "| 196|  242|     3|\n",
      "| 186|  302|     3|\n",
      "|  22|  377|     1|\n",
      "| 244|   51|     2|\n",
      "| 166|  346|     1|\n",
      "| 298|  474|     4|\n",
      "| 115|  265|     2|\n",
      "| 253|  465|     5|\n",
      "| 305|  451|     3|\n",
      "|   6|   86|     3|\n",
      "|  62|  257|     2|\n",
      "| 286| 1014|     5|\n",
      "| 200|  222|     5|\n",
      "| 210|   40|     3|\n",
      "| 224|   29|     3|\n",
      "| 303|  785|     3|\n",
      "| 122|  387|     5|\n",
      "| 194|  274|     2|\n",
      "| 291| 1042|     4|\n",
      "| 234| 1184|     2|\n",
      "+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check returned data\n",
    "utility_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do a test/train split using the pyspark method\n",
    "train, test = utility_spark_df.randomSplit([0.8, 0.2], seed=427471138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als_model = ALS(\n",
    "    itemCol='movie',\n",
    "    userCol='user',\n",
    "    ratingCol='rating',\n",
    "    nonnegative=True,    \n",
    "    regParam=0.1,\n",
    "    rank=10\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "fit_als_model = als_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|user|movie|rating|\n",
      "+----+-----+------+\n",
      "|   1|  100|     5|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# subselect data for user 1 only\n",
    "utility_1 = utility_df[utility_df[0] == 1]\n",
    "# subselect user 1 data for movie 100 only\n",
    "one_row_pandas_df = utility_1[utility_1[1] == 100]\n",
    "# convert to single-user, single-movie spark data frame\n",
    "one_row_spark_df = spark.createDataFrame(one_row_pandas_df, [\"user\", \"movie\", \"rating\"])\n",
    "# show result\n",
    "one_row_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+----------+\n",
      "|user|movie|rating|prediction|\n",
      "+----+-----+------+----------+\n",
      "|   1|  100|     5|  4.512069|\n",
      "+----+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use model to create predictions on our single-row df\n",
    "fit_als_model.transform(one_row_spark_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+----------+\n",
      "|user|movie|rating|prediction|\n",
      "+----+-----+------+----------+\n",
      "| 642|  148|     5|  3.730146|\n",
      "|  27|  148|     3| 2.7040005|\n",
      "| 330|  148|     4| 4.1282973|\n",
      "| 416|  148|     5| 3.6591568|\n",
      "| 935|  148|     4|   4.45987|\n",
      "| 297|  148|     3| 2.5351734|\n",
      "| 178|  148|     4| 3.4242537|\n",
      "| 923|  148|     4| 3.4890065|\n",
      "| 455|  148|     3|  2.942392|\n",
      "| 891|  148|     5| 3.7899954|\n",
      "| 930|  148|     1| 3.4828787|\n",
      "| 434|  148|     3| 4.2464223|\n",
      "| 438|  148|     5| 3.9753437|\n",
      "| 293|  148|     1| 2.0894637|\n",
      "| 793|  148|     4| 2.9233704|\n",
      "| 320|  148|     4| 3.4986992|\n",
      "| 893|  148|     3| 2.8671303|\n",
      "| 396|  148|     4|  3.521694|\n",
      "|  90|  148|     2| 3.1481078|\n",
      "| 203|  148|     3| 3.2632225|\n",
      "+----+-----+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use model to predict for our test data\n",
    "fit_als_model.transform(test).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve item factor list from fitted model (for movie 100)\n",
    "movie_100_f = np.array(fit_als_model.itemFactors.filter('id = 100').collect()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve user factor list from fitted model (for user 1)\n",
    "user_1_f = np.array(fit_als_model.userFactors.filter('id = 1').collect()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5120691326121438"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dot product of these two lists is \n",
    "# the predicted rating for user 1 on movie 100\n",
    "np.dot(movie_100_f,user_1_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get prediction for training data\n",
    "recomendations_train = fit_als_model.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get prediction for test data\n",
    "recomendations_test = fit_als_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this creates a table we can query with SQL\n",
    "recomendations_train.createOrReplaceTempView(\"recomendations_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   79953|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use SQL query to demonstrate there are no nulls in our dataset\n",
    "result = spark.sql(\"\"\"SELECT count(*) \n",
    "                    FROM recomendations_train \n",
    "                    WHERE user is not null\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|  3.963504|\n",
      "|  3.440942|\n",
      "|  3.197185|\n",
      "| 3.8421497|\n",
      "| 3.6884224|\n",
      "| 4.0891385|\n",
      "| 3.1011424|\n",
      "| 3.6093917|\n",
      "| 3.2182221|\n",
      "| 3.6423123|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"SELECT distinct(prediction) \n",
    "                    FROM recomendations_train \n",
    "                    limit 10 \"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   76919|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = spark.sql(\"\"\"SELECT count(*) \n",
    "                    FROM recomendations_train \n",
    "                    WHERE prediction > 2\n",
    "                    limit 10\"\"\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
